{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Trainingsdata: (60000, 28, 28)\n",
      "Dimension Picture No. 5: (28, 28)\n",
      "Label of Picture No. 5: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape Trainingsdata: {}\".format(train_images.shape))\n",
    "print(\"Dimension Picture No. 5: {}\".format(train_images[5].shape))\n",
    "print(\"Label of Picture No. 5: {}\".format(train_labels[5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "NrTrainimages = train_images.shape[0]\n",
    "NrTestimages = test_images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "randindex = random.randint(0,60000)\n",
    "plttitle = \"Trainpicture Nr. {} \\n Class: {}\".format(randindex,train_labels[randindex])\n",
    "plt.imshow(train_images[randindex].reshape(28,28),cmap='gray')\n",
    "plt.title(plttitle)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "#train_images[randindex]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGDIR = \"\\log\"\n",
    "my_tensorboard = TensorBoard(log_dir = LOGDIR, \n",
    "                            histogram_freq=0, \n",
    "                            write_graph=True, \n",
    "                            write_images=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 64)          51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "features (Dense)             (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 192,202\n",
      "Trainable params: 192,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mnist_inputshape = train_images[0].shape\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(5,5), \n",
    "                 activation = 'relu', \n",
    "                 input_shape=mnist_inputshape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(5,5), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', name='features'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/6\n",
      "60000/60000 [==============================] - 46s 762us/sample - loss: 0.3970 - acc: 0.8724 - val_loss: 0.0613 - val_acc: 0.9800\n",
      "Epoch 2/6\n",
      "60000/60000 [==============================] - 44s 731us/sample - loss: 0.1170 - acc: 0.9660 - val_loss: 0.0431 - val_acc: 0.9855\n",
      "Epoch 3/6\n",
      "60000/60000 [==============================] - 43s 722us/sample - loss: 0.0861 - acc: 0.9747 - val_loss: 0.0310 - val_acc: 0.9897\n",
      "Epoch 4/6\n",
      "60000/60000 [==============================] - 45s 758us/sample - loss: 0.0735 - acc: 0.9783 - val_loss: 0.0292 - val_acc: 0.9901\n",
      "Epoch 5/6\n",
      "60000/60000 [==============================] - 49s 817us/sample - loss: 0.0642 - acc: 0.9808 - val_loss: 0.0246 - val_acc: 0.9920\n",
      "Epoch 6/6\n",
      "60000/60000 [==============================] - 49s 822us/sample - loss: 0.0578 - acc: 0.9829 - val_loss: 0.0249 - val_acc: 0.9913\n"
     ]
    }
   ],
   "source": [
    "my_batch_size = 128\n",
    "my_num_class = 10\n",
    "my_epochs = 6\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='Adam', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, \n",
    "        batch_size=my_batch_size, \n",
    "        callbacks=[my_tensorboard], \n",
    "        epochs=my_epochs, \n",
    "        verbose=1, \n",
    "        validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 294us/sample - loss: 0.0249 - acc: 0.9913\n",
      "Test Verlust: 0.024882994672410133\n",
      "Test Genauigkeit: 0.9913\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_images, test_labels)\n",
    "print('Test Verlust:', score[0])\n",
    "print('Test Genauigkeit:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cnn.h5')\n",
    "model.save_weights(\"cnn_weights.h5\")\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 1234\n",
    "plt.imshow(test_images[image_index].reshape(28, 28),cmap='Greys')\n",
    "pred = model.predict(test_images[image_index].reshape(1, 28, 28, 1))\n",
    "print(pred.argmax())                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-5cd903d8bcd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mnist_model.tflite\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtflite_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cnn' is not defined"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(cnn.h5)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "open(\"mnist_model.tflite\", \"wb\").write(tflite_model)\n",
    "\n",
    "#model.save('CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
